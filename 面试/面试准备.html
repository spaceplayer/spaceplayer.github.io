<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="xinzhi">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>面试准备 - 新志小站</title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="..">新志小站</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">首页 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../index.html">新志的个人小站</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">算法与数据结构 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">算法</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../xxx">动态规划</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">题目</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../算法/LeetCode题目总结.html">LeetCode题目总结</a>
</li>
            
<li >
    <a href="../算法/剑指offer.html">剑指offer</a>
</li>
            
<li >
    <a href="../算法/面试题总结.html">面试题总结</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">推荐系统 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../推荐系统/FM算法汇总.html">FM算法汇总</a>
</li>
                                    
<li >
    <a href="../推荐系统/深度学习召回模型.html">深度学习召回模型</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">自然语言处理 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../自然语言处理/BERT及ERNIE学习.html">预处理模型</a>
</li>
                                </ul>
                            </li>
                            <li >
                                <a href="../xxx">机器学习</a>
                            </li>
                            <li >
                                <a href="../xxx">深度学习</a>
                            </li>
                            <li >
                                <a href="../xxx">强化学习</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">语言学习 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#">C++</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../语言/CPP笔记.html">C++笔记</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">Python</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../语言/Python笔记.html">Python笔记</a>
</li>
            
<li >
    <a href="../语言/Python高效编程.md">Python高效编程</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#">设计模式</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../语言/设计模式.html">设计模式</a>
</li>
    </ul>
  </li>
                                    
<li >
    <a href="../语言/多进程多线程.html">多进程多线程</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">常用工具 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../工具/如何构建自己的博客.html">如何构建自己的博客</a>
</li>
                                    
<li >
    <a href="../工具/常用Linux命令.html">常用Linux命令</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">读书笔记 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../读书笔记/论美国的民主.md">论美国的民主</a>
</li>
                                </ul>
                            </li>
                            <li >
                                <a href="../xxx">随笔记事</a>
                            </li>
                            <li >
                                <a href="../xxx">年度计划</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li>
                                <a href="https://github.com/spaceplayer/mkdocs_blog/blob/mkdocs_blog/docs/面试/面试准备.md">Edit on spaceplayer/mkdocs_blog</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#_1">面试准备</a></li>
        <li class="main "><a href="#_2">简历修改</a></li>
            <li><a href="#1-3">零、自我介绍 1-3分钟</a></li>
            <li><a href="#_13">爱库存项目</a></li>
            <li><a href="#-">- 剔除单一值、缺失值比例过大的字段, 剔除业务上关联不大的表字段</a></li>
            <li><a href="#_14">一、项目篇</a></li>
            <li><a href="#_23">二、机器学习 深度学习</a></li>
            <li><a href="#_24">三、基础算法</a></li>
            <li><a href="#_25">四、概率统计和矩阵</a></li>
            <li><a href="#_26">五、推荐算法</a></li>
            <li><a href="#cuda">六、CUDA编程</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="_1">面试准备</h1>
<pre><code class="mermaid">gantt
dateFormat  YYYY-MM-DD
title 面试准备

section 项目篇
腾讯广告算法大赛                        : crit, active, des1, 2019-04-05, 2019-04-20
爱库存主页推荐项目                       :crit, des2, after des3, 2d
知识图谱助力电影推荐         :crit,  des3, 2019-04-14, 2019-04-20

section 机器学习+深度学习
GBDT                                        :des4,  2019-04-09, 2019-04-10
LightGBM                    :des5,  2019-04-09, 2019-04-10
XGBoost                     :des6,  2019-04-09, 2019-04-10

section 基础算法
LeetCode题目               : des20,  2019-04-14, 2019-05-01
动态规划                                : des21,  2019-04-09, 2019-04-10
DFS+BFS                              : des22,  2019-04-09, 2019-04-10

section 概率统计和矩阵
张宇概率论复习                     : des23,  2019-04-09, 2019-04-10
张宇矩阵复习                          : des24,  2019-04-09, 2019-04-10

section 推荐算法
推荐系统实践复习                : des25,  2019-04-09, 2019-04-10
推荐算法课PPT复习              : des26,  2019-04-09, 2019-04-10
</code></pre>

<h1 id="_2">简历修改</h1>
<p>3.结果量化</p>
<p><strong>个人信息+需求分析+匹配岗位的特征+逻辑/事例论证+礼貌自信+反复练习=offer</strong></p>
<p>因此， “面试准备”最科学的策略不是“面面俱到”，而是只需<strong>反复演练自己的“最佳亮点”</strong>、以及<strong>如何结束面试</strong>就够了（所以那些回答说自我介绍要怎么精修“内容”的都很不靠谱）。</p>
<h2 id="1-3">零、自我介绍 1-3分钟</h2>
<p>面试官你好, 我叫郑新志, 黑龙江人, 现在是北航软件工程研究生二年级.</p>
<p>本科毕业后我在互联网金融公司做过一年的Java开发工程师, 再此期间我接触到机器学习的一些知识, 之后想系统的学习下关于算法相关的内容, 就考取了北航研究生. 在去年7月份, 我报名并通过考核参加了北大的Deecamp训练营, 利用美团提供的数据做了一个利用知识图谱做电影推荐的课题, . 在研一期间 我主要在创新奇智公司担任算法实习生, 从0到1的搭建了爱库存活动推荐系统算法线下部分的任务. </p>
<p>我的短期目标是找一个利用机器学习、自然语言处理等技术去解决海量数据做推荐和广告等方面的工作.[可选]长期目标是通过不断地学习实践, 不断地积累自己的技术储备, 不断挑战新问题, 形成自己的技术体系框架, 成为一个算法技术专家.</p>
<p>这些是我的自我介绍, 谢谢!</p>
<h5 id="_3">项目背景</h5>
<p>爱库存推荐系统项目, 爱库存一家B2B2C的社交电商公司，要给他们的app做推荐系统，我主要负责完成主页活动推荐任务的线下模型开发，业务目标是提升活动的购买转化率cvr. 主要有3部分工作, 前期梳理业务场景, 定义问题, 先按照业务经验从各个库表中选取合适的原始特征, 完成一个基础的LR baseline, 中期做EDA, 数据清洗, 后期特征工程分析特征有效性及模型调参, 最终线下最好的单模型AUC是0.787</p>
<p>这是个社交电商推荐系统的任务, 和传统的电商推荐有两点不同, 用户不是终端用户而是小B用户, 待推荐item不是商品而是活动. 带来的用户方面的问题就是小B用户偏好较弱, 我通过小B历史价格偏好和过去T天内各品牌点击率和转化率特征来刻画小B朋友圈的偏好, 第二个问题是97%的活动生命周期在2-3天, 实时活动点击率转化率, 我们用品牌和品类的相关特征去代表活动, 并补充商品集合的特征. 原始特征来源于用户特征, 活动特征.</p>
<p>特征工程的主要工作, </p>
<p>1.用户生成T天内的各品牌品类的历史点击率转化率, 活动生成T天内的各品牌品类的历史点击率转化率</p>
<p>2.时间方面的特征, monthOfYear weekOfMonth weekdayOfWeek hourOfDay  是否节假日 是否周末 用户上次登录聚现在的时间 上次购买距现在时间 距离活动上线时间</p>
<p>3.价格特征基于分位点做分桶(长尾分布)</p>
<p>4.利用ip去填充地址缺失, 并利用ip做层次编码</p>
<p>4.用户特征和活动特征中基数较小的进行交叉特征及相关的统计特征(ctr cvr), 例如居住地性别和品牌的交叉, 年龄和活动转化率的交叉, 时间和活动的交叉, 时间和用户的交叉</p>
<p>5.特征值较多的特征使用Target编码编码, 特征值在4个以内的用onehot编码, </p>
<p>遇到的问题?</p>
<p>如何利用短文本</p>
<p>遇到的问题 文本特征embedding训练个LR模型 预测个ctr的概率 放入模型当做一维特征</p>
<p>为什么不先训练模型的ctr预估 再训练cvr预估?</p>
<p>这个是正常的思路 但我们的曝光数据一直在埋点中 还没有上线 所以难以有监督的学习到ctr</p>
<p>样本负例的选取?</p>
<p>skip-above 用户点击的item位置以上的展现才可以作为负例</p>
<p>如何解决</p>
<p>不同于CTR预估问题，CVR预估面临两个关键问题：</p>
<ol>
<li><strong>Sample Selection Bias (SSB)</strong> 转化是在点击之后才“有可能”发生的动作，传统CVR模型通常以点击数据为训练集，其中点击未转化为负例，点击并转化为正例。但是训练好的模型实际使用时，则是对整个空间的样本进行预估，而非只对点击样本进行预估。即是说，训练数据与实际要预测的数据来自不同分布，这个偏差对模型的泛化能力构成了很大挑战。</li>
<li><strong>Data Sparsity (DS)</strong> 作为CVR训练数据的点击样本远小于CTR预估训练使用的曝光样本。</li>
</ol>
<p>一些策略可以缓解这两个问题，例如从曝光集中对unclicked样本抽样做负例缓解SSB，对转化样本过采样缓解DS等。但无论哪种方法，都没有很elegant地从实质上解决上面任一个问题。</p>
<p>用户的客户端类型</p>
<p>用户消费水平</p>
<p>活动方面 活动代表的用户群特征</p>
<p>选出最重要的两个变量，并计算他们相互之间、以及与其它变量之间的二阶交叉作用并放入模型中，比较由此产生的模型结果与最初的线性模型的结果</p>
<p>没有性别特征 通过特征子集学习一个性别概率(无监督)</p>
<p>我是这么思考这个任务的, 1.界定问题: 这是个社交电商推荐任务, 2.分析问题, 找出和其他电商推荐系统有哪些相同异同点, 相同点可以借鉴过来, 异同点单独分析处理, 而本任务和常见的电商推荐任务区别主要有两点: 第一点区别它的用户不是终端消费者, 而是个小B店主(代购), 那么我们不能单纯的只分析小B的偏好, 更要统计小B朋友圈子终端用户的偏好, 这部分群体偏好这部分我们利用小B的历史消费行为生成价格分布特征和T天内各品牌品类的点击率转化率特征来表征群体用户偏好. 小B的偏好+群体偏好是我设计的用户画像; 第二点区别我们推荐的不是商品, 而是爱库存公司定义的活动, 活动的特点是一个活动是一个品牌商的一类商品(或者可以说是一类商品集合), 接近98%的活动生命周期都是在2-3天, 所以所有的活动都面临着冷启动的问题, 这导致我们如果使用传统的CF模型效果会很差, 我们首先用活动最显著的品牌和品类特征表征活动, 其次使用活动本身的特征,  最后还有一个很关键的一部分特征, 就是如何刻画这个活动商品集合的特点并补充到活动中去, 例如利用商品集和的价格分布特征, 商品类别Embedding集合取均值.这三部分特征是活动相关的画像. 有了用户画像,活动画像, 再增加场景方面的特征, 月份, 周几, 节假日特征等.</p>
<p>AUC是什么 代表什么</p>
<h3 id="_4">特征选择部分</h3>
<p>基于统计的特征选择。说白了就是直接通过某个指标来判断他对预测的共现程度，如pearson相关系数</p>
<h4 id="pearson">pearson相关系数</h4>
<p>要理解person,首先理解协方差, 协方差表示连两个变量的相互关系 COV(X, Y) = SUM((Xi - X_mean)(Yi - Y_mean)) / (n - 1)</p>
<p>person相关系数是X, Y协防差除以两个变量的标准差(消除量纲的差异)</p>
<p><img alt="image-20190923161956518" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190923161956518.png" /></p>
<p>由上图可以总结，当相关系数为1时，成为完全正相关；当相关系数为-1时，成为完全负相关；相关系数的绝对值越大，相关性越强；相关系数越接近于0，相关度越弱。</p>
<h4 id="_5">决策树如何处理缺失值</h4>
<h4 id="xgboost">XGboost缺失值处理</h4>
<p><img alt="image-20190924084551752" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190924084551752.png" /></p>
<h4 id="gbdt-vs-xgboost">GBDT vs XGBoost</h4>
<p><img alt="image-20190924084924184" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190924084924184.png" /></p>
<h4 id="_6">直方图算法</h4>
<p><img alt="image-20190924091632824" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190924091632824.png" /></p>
<h4 id="_7">进程和线程区别</h4>
<p><img alt="image-20190924092019744" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190924092019744.png" /></p>
<p>负样本构建</p>
<h5 id="_8">还存在的问题</h5>
<p>1.EDA引出的活动上线排期设计辅助推荐
2.位置偏见如何解决
3.时间衰减如何解决</p>
<p>如何思考召回排序的 无召回直接排序</p>
<h5 id="_9">效率优化</h5>
<p>矩阵运算 多进程</p>
<h5 id="_10">应用技术</h5>
<p>LR GBDT LightGBM FM</p>
<p>word2vec</p>
<p>贝叶斯优化</p>
<h5 id="_11">效果</h5>
<h5 id="_12"></h5>
<h2 id="_13">爱库存项目</h2>
<p>数据预处理</p>
<h2 id="-">- 剔除单一值、缺失值比例过大的字段, 剔除业务上关联不大的表字段</h2>
<p>target encoding</p>
<h2 id="_14">一、项目篇</h2>
<h3 id="11">1.1 腾讯广告算法大赛</h3>
<h4 id="111">1.11 题目描述</h4>
<p><strong>[相似人群扩展|Lookalike]</strong> 基于广告主提供的目标人群, 从海量的人群中找出和目标人群相似的其他人群.</p>
<p><strong>数据量</strong>是某连续30天的数据</p>
<p><strong>评价指标</strong>是m个种子包的平均AUC</p>
<p><strong>PU learning问题</strong>：Positive and unlabeled learning</p>
<h4 id="112-idea">1.12 算法idea</h4>
<p><strong>数据集划分</strong>: 随机划分(如果有时间容易造成特征穿越)和按时间划分</p>
<p><strong>数据规模大:</strong> 数据下采样, 特征选择, 没验证出一个有效特征存到硬盘上面</p>
<p><strong>单模型</strong>: LightGBM相比XGBoost有着精度相似, 训练速度快好几倍的优点</p>
<p><strong>模型融合</strong>: 前期特征工程, 后期模型融合, 最好要了解每个模型适合什么样的特征工程, 而不是所有的单模型共用一套特征</p>
<p><a href="https://zhuanlan.zhihu.com/p/26820998">Kaggle 数据挖掘比赛经验分享</a></p>
<p><a href="">比赛后期大招之Stacking技术分享</a></p>
<p><strong>无时间特征时统计特征如何防止特征穿越:</strong> k-fold统计。在构造和label有关的特征时，比如转化率，为了防止信息泄露，只能将数据分成k份，用k-1份来统计剩下的1份，重复k次。</p>
<p><strong>内存:</strong> 尽可能减少Numpy, pandas库使用, 用list可大量减少内存依赖</p>
<p><strong>内存:</strong> 使用h5格式存储, 数据类型主要使用int8和int16, 提高读写速度</p>
<p><strong>小类别归为"其他":</strong> 防止过拟合</p>
<p><strong>模型(第三周周冠军nju分享):</strong> 对于List类型的特征，我们目前是对embedding向量做了mean pooling。在模型训练过程中我们没有使用dropout也没有进行正则化。我们在模型中加入了batch normalization。参数的选择方面，我们的模型训练过程只迭代一次，batch size通常设为2000以上，Adam优化器学习率设为0.001到0.01之间。此外，在我们之前的实验中，多次训练模型取平均也能提高不少效果，大家也可以尝试一下。</p>
<p><strong>优化目标:</strong> 由于本次大赛的评价指标是AUC指标，而AUC指标实际上计算的是一种pairwise的损失，因此无法直接对其求导优化。常见的方法中，使用learning to rank中pairwise的方法进行优化的比较多，效果也很好。然而这类方法时间复杂度太高，因此在比赛中我们也尝试了一些替代的优化目标。最简单的是log loss，这也是效果最好也最常用的损失函数。我们还尝试了一些其他的优化目标，如hinge loss, 正负样本得分差等，效果也都很好。我们在综合了这些优化目标之后，效果也取得了一定的提升。</p>
<p><strong>one hot之后的categorical features维度很高，这种高维度的特征直接和低维度的数值特征一起输入到模型里面，是不是会对这些低维度的特征产生一种稀释作用，将他们的重要性降低了。面对这种情况，有什么好的处理方法吗？</strong></p>
<p>答：首先，未必要使用one-hot这种编码方式。one-hot在NLP领域中有明显地效果提升，但未必会在Lookalike问题中会有同样的明显效果。所以，这里需要先对one-hot编码方式的优点缺点做个评估。如果要使用one-hot方式，还需要平衡优点和缺点哪个影响更大。这里提供一个思路来解决特征稀释的问题，或许可以尝试通过feature weighting 的方式来降低特征稀释带来的负面效果。</p>
<p><strong>特征工程对获得一个好的结果很重要，那在CTR预估中，我们是如何人工地去提取交叉特征呢。比如我知道地点和食物这两个特征的交叉很关键，那如何生成关于地点和食物这两个特征的交叉特征呢？是直接相乘作为新的特征吗？</strong></p>
<p>答：首先要对每个变量进行独热编码（one-hot encoding），分别得到一个只有0/1值的向量，然后对不同变量对应向量进行笛卡尔积，这样就可以进行特征组合，特征组合后得到的向量长度是之前2个变量的向量长度之积。</p>
<p><strong>我想请问一下FFM的事情，先FFM再加gbdt没有效果哦，FFM那个开源代码的应用能帮我讲解一下吗？</strong> </p>
<p>答：首先是FFM或者FM，这样的模型适用于输入特征是高维稀疏变量，而树模型对输入数据格式没有要求；其次，FM的复杂度是O(N^2)，而FFM的复杂度可以得到O(N^3)，如此高的时间复杂度，有可能训练的时候没有完全收敛，使得效果有所影响；最后，其实这2个是不同体系的模型，可以考虑分别训练，最终做一个模型的ensemble。</p>
<p><strong>一般怎么样重新组合特征或者在原有特征的基础上提取新的特征？</strong></p>
<p>答：一般有三种思路：1）使用特征交叉（cross）的方法，即先对每个变量进行独热编码，分别得到一个只有0/1值的向量，然后对不同变量的向量进行笛卡尔积，这样就可以进行特征组合；2）使用树模型（如GBDT, XGboost等）对数据进行拟合，自动得到特征组合（从根部到叶子节点对应路径的多个特征就是一个特征组合结果）；3）使用DNN，FM等对原始特征进行embedding，减少稀疏性，也增加了特征表达能力。</p>
<p><strong>数据正样本、负样本是如何采样出来的？</strong></p>
<p>答：我们的评估指标AUC对正负样本的比例也是不敏感的，所以也不会影响选手做题。</p>
<p><strong>对于正负样本很不均衡时，有什么比较好的解决办法吗？</strong></p>
<p>答：一是用降采样或过采样的方式，使得正负样本数量持平，本题中可以对负例进行降采样，这样也能加速模型训练过程；二是保持正负样本数量不变，训练模型时对正负样本取不同的权重。此外，可以使用不同的随机种子进行采样，训练相同的模型，然后进行模型的集成，这样可以提升效果。</p>
<p><strong>我使用了CTR预估中经常使用Deep FFM以及一些变体，发现还是没有树模型xgboost好，并没有论文中阐述的很优异的性能变现。可能是我调参还存在问题，还是说这些模型实用场景的差距比较大？是否有个通用的模型来解决这个问题？</strong></p>
<p>答：据我所知，CTR里面确实FFM这些模型用的更多一些，树模型比较少在用，因为它的复杂度比较高。你刚说深度模型和树模型效果差不多，其实已经可以说明问题了。在工业界和学术界确实存在一些gap，工业界除了考虑AUC这些离线指标，还会更多地考量线上实时响应速度，以及做特征是否方便、训练时间是否很快、模型迭代更新的速度是否很快、这些算法是否可以online，但是树模型其实不太好做到这些。</p>
<p><strong>我在做一个权重学习的特征抽取方法，需要一列一列的抽取，但是用了one-hot后特征有几十万维，有没有一种降维的方式减少特征维度？</strong></p>
<p>答：关于特征重要程度的评判，我提供几个思路：一是可以在做one-hot之前做特征重要度的学习，二是用sparse coding的数据表达方式，在另一维空间中可以控制维度大小，做feature selection，再做decoding，找到原始特征中的重要程度。可以试下这个问题中这种思路是否有效。</p>
<p><strong>我在做特征选择的时候，如果手动删除一列列特征，复杂度太高，还用了些相关系数的方法，效果就更差了，请问有没有什么好的特征选择方式呢？</strong></p>
<p>答：我所了解的特征选择主要包括两种类型，一种是filter base，一种是wrapper base，我了解它们多数是用一些recursive feature elimination的方式，循环地删除一个或多个特征，然后retrain模型再删除，这种方式复杂度较高，但是可能比模型自带的选特征方式效果会好些。一些paper会在RFE的模型中做一些简化，比如删掉一个或多个特征后，不做retrain，也能达到类似的效果，不过相比于LR自带的特征选择复杂度还是高些，这边是一个trade-off。 (Filter、Wrapper、Embedded)</p>
<p><strong>one hot 特征和统计特征: </strong>在初赛时候我们发现one-hot的特征和我们的统计特征差异性很大， 所以我们在自己近百维的统计特征上直接加入了one-hot的特征，带来了7个千左右的提高，而我们的统计特征为了防止信息泄露都是采用5-fold的方式提取的。</p>
<p><strong>模型: </strong>初赛时我们一共训练了三种模型，分别是lgb，deepfm，deepffm，其中lgb分数最高，并通过简单的加权平均得到了不错的分数</p>
<p><strong>FFM baseline: </strong>https://zhuanlan.zhihu.com/p/36302396</p>
<p><strong>普通离散特征分桶:</strong> FFM不仅能使用单纯的id信息，也可以通过对连续值特征分桶离散的方式，使用连续值特征。我们选的是等距离分成10组，将部分lgb模型的连续值特征（需要与单纯的id相关性较低），输入FFM之后，FFM初赛A榜达到了750的分数。</p>
<p><strong>统计特征分桶: </strong>本次赛题在做特征工程的时候，我们会发现广告和用户之间的交叉特征的重要性靠前。虽然FFM可以自动学习特征之间的两两交叉，但是我们感觉需要更显式的指出这种交叉，同时可以等同于实现了部分强特征的三交叉和四交叉。为此我们将lgb模型中交叉转化率特征分桶离散输入模型，做了这部分的预处理后，FFM初赛A榜达到了0.7557的线上分数。</p>
<p><strong>模型融合:</strong> FFM模型的预测和lgb还有nn模型的预测存在着较大的差异性，融合效果显著。</p>
<p><strong>dataframe读写利器:</strong> 进入复赛后数据较大，使用pickle和hdf存储中间结果时会出现一些存储报错。这里我们推荐大家使用feather这个包，安装完这个包后，可以直接将dataframe对象存储为feather格式，又快又好。</p>
<p><strong>北大开源的xlearn: </strong>，优点是同样的预测效果下速度比libffm快了几倍，然后可以设置auc作为观测指标，并且可以直接通过python调用。</p>
<p><strong>FFM重要参数:</strong> FFM比较重要的参数有隐层向量维度k，学习率lr还有正则系数lambda</p>
<p><strong>流式处理:</strong></p>
<p><strong>组合特征</strong>： (creativesize gender) (advertised LBS )</p>
<p><strong>开源比赛: </strong>kaggle criteo, avazu, avito, pCTR 特征工程部分，CTR 问题的常见特征。</p>
<p>ID 交叉特征，ID 统计特征等，常见的可以从参考 Kaggle 之前 Criteo, Avazu, Avito 的点击率预估比赛开源方案。</p>
<hr />
<p>2017 腾讯赛</p>
<p><strong>点击率 vs 转发率预估:</strong> <a href="https://mp.weixin.qq.com/s/EBnUIaIUYA5Vhm2fFMnuJA">点击转化对比</a></p>
<p><strong>对于正负样本很不均时比较好的解决办法是什么，还有就是对于多个特征的组合一般用什么样的思路？</strong></p>
<p>在 imbalance 问题中，通常可以对样本较多的负例进行下采样（保持正例不变），可以加速模型的训练。另外，为了提升效果，可以使用不同的随机种子进行采样，训练相同的模型，然后进行模型的集成。可以参考下 Avito 点击率预估比赛中，Owenzhang 的建模方式。特别需要提醒的是，本次比赛的评估指标是 logloss，其对样本的正负比例分布较为敏感，在进行采样，改变了样本的原始分布后，一般需要对预测结果进行 calibration，使得其接近原始数据的分布。</p>
<p>至于特征组合方面，需要具体问题具体分析。如果是 ID 特征，可以简单的做笛卡尔乘积交叉。如果是数值型特征（譬如某些统计量），可以进行加减乘除变换等。另外，推荐尝试 XGBoost 和 DNN 等模型，可以从数据里面学到较优的特征组合方式。</p>
<p><strong>不同长度的多值特征处理: </strong> 数据清洗部分，CTR 问题有没有什么经典的地方，针对这个数据集更好</p>
<p>比较有挑战的是 App 数据，每个用户安装的 App 数目不一样，如何转换成特征，也是一个挑战。可以参考下 TalkingData 在 Kaggle 上面的比赛。</p>
<p><strong>FFM vs xgboost</strong></p>
<p>FM/FFM 对于大量稀疏 ID 类的特征会较好，但可能更依赖与特征工程（样本特征的组织形式）；XGBoost 几乎是 off-the-shelf，运行速度较快。FFM 和 XGBoost 在具体应用场景的效果差异，跟任务，数据，特征还有使用方式有关，我目前还没有看到哪一个是绝对通用的好的。在 Criteo 和 Avazu 点击率预估比赛中，前几名几乎都是用 FFM，然而在随后的 Avito 点击率预估比赛中，冠军 Owenzhang 的经验是“ XGBoost 要比 FFM 好很多”。</p>
<p><strong>类别特征是否onehot</strong></p>
<p>这里不清楚选手使用的模型。如果 LR/DNN，进行 One-hot 是合理的。如果使用 RF/XGBoost 等树模型，可以不用 One-hot，让这些模型把这个类别特征当作数值型特征，然后进行分裂。尤其是当类别特征的取值较多的情况下，譬如100W，可以直接输入 XGBoost。当然也有其他更好的特征设计的方法。</p>
<p><strong>针对本次比赛给出的时间刻度我们无法有效建立线下的验证集，问专家怎么看？</strong></p>
<p>本次比赛提供的数据是时序数据，一般按照时间先后划分本地训练集和验证集。这个问题其中的一个难点是训练数据最后几天 label = 0 的数据由于回流延迟可能存在噪声，在这种情况下，如何构造一个有效的验证集也是选手们需要考虑的一个挑战。</p>
<p>一个提示，数据中提供了回流时间，可以一天、两天分别能回流多少数据。这样可以分析出自己构造的验证集和真实数据的差异。另一个提示是，转化数据是广告主提供的，也是个线索。</p>
<p><strong>线上及线下的一致: </strong></p>
<p>对于这种比赛，首先你必须做到CV和线上的成绩相差不大，其次 CV 和线上的成绩应该是同增同减的。否则后面你所做的事情都是白费功夫，因为 CV 根本体现不出来特征的好坏。为了同步 CV 和线上成绩，我花了两天的时间去做这件事情。</p>
<p>比赛初期最重要的就是构建有效的训练集，能够尽量与线上情况同步，数据集划分方案大家可以参考腾讯广告算法大赛官方公众号推荐参考的几个比赛的信息。</p>
<p><strong>如何评价特征好坏: </strong>其实一个特征的好坏程度，你可以简单的通过 groupby(’feature’,’label’) 来看出特征的好坏程度，如果某个特征在不同的取值上，0和1的比例和平均比例相差很大，那么这个特征是有效的。又或者可以看方差，这样可以省下许多时间去测试特征的好坏。</p>
<p><strong>特征分布是否一致</strong>特征分布主要考虑的是线上和线下的分布差异。由于这次比赛的数据具有时序性，并且很多选手也因为在提取特征时因为信息泄露的原因导致线下成绩提升而线上成绩降低，这些问题都可以通过特征值的分布差异来排除掉，当分布不一致的特征，我们应该优先删除。特征分布差异，简单的可以通过线下和线上特征值的均值、标准差差异来考虑，或者基于其它的统计学的方法。(如何得知线上特征的均值 标准差)</p>
<p><strong>加入某个特征线下logloss下降了很多，但是线上logloss反而升高了。</strong></p>
<p>​       1．这个特征是不是信息泄露了，比如使用了未来的数据来预测现在。能不能重新构造类似的特征来规避时间。</p>
<p>​       2.测试集是不是没有这样的特征。比如训练集虽然使用了点击时间之前 app_action 的数据，可是训练集有当天的action信息，而测试集没有当天的 action 信息。因此造成了训练集有这样的特征，而测试集没有。</p>
<p><strong>特征生成: </strong> 一是拍脑门（比如one-hot、各种的转化率、点击量等特征）, 一方面是通过其它模型的结果来生成各种特征，其中能否通过深度学习来产生新的特征？LDA来分析用户和app之间的关系？特征之间不断的组合能否产生比较好的特征？这需要通过对数据的理解，不断的尝试和分析。不过我的并不建议那么快的考虑用其它的模型来生成特征，毕竟这种方法生成的特征有时候并不能很好的理解，并且需要的工作量也比较大，有时候生成的特征也并不一定有效果。</p>
<p><strong>特征工程思路: </strong>（1）不加没用的特征：特征之间如果存在强相关性会给模型造成干扰。需要控制变量，保留最有效、精简的特征。我们是使用逐一删除，对比实验来验证特征有效性。</p>
<p>（2）多看比赛经验、相关论文：站在巨人的肩膀上分析问题，常常能够事半功倍。我们借鉴了CTR预估等相关比赛的经验，参考了Kaggle的历届比赛分享，也看了相关获奖队伍的代码，受益匪浅。对于加特征时需要考虑的细节变得更加清楚。</p>
<p>（3）观察数据，因地制宜找特征：特征工程的构建需要紧密联系数据特点。判断某个特征是否有意义，不能只是空想，要做统计分析。我们可以关注一个特征在不同标签中的比例，关注是否有哪些特殊的情况会对转化有很大的影响，这种情况的占比是否大，是否有加为特征的必要……这一系列的问题都需要观察数据，做恰当的统计进行分析。</p>
<p><strong>特征的组合</strong>。比如positionid和connectiontype的组合统计是一个很强的特征，但是单纯统计positionid和connectiontype其实是没有办法表达出这个特征的。这个时候就需要做组合特征的统计，比如统计它们共同出现的次数，转换次数，转换率等。对于哪些组合特征比较有用，</p>
<p><strong>用户id的补充:</strong> 对user_app_installed和user_app_actions两个表做一些简单的历史统计。因为userid维度很高，所以在train.csv里面很难得到一个比较好的userid的特征表达的。所以可以利用那两个安装列表，统计出userid的历史安装次数作为特征的补充。同样地，也可以统计出appid的历史安装次数。通过映射userid和user.csv，appid和app_category.csv，还可以得到其他特征的一些统计值。做完这个最起码可以有万分之五的效果提升。</p>
<p><strong>多注意一些重复的数据</strong>，train.csv中有很多数据是重复出现的，除了label不同以外，其他的特征是全部一样的。很多小伙伴对这些数据选择了去重，但是不幸的是，测试集中也有类似数据的出现。去重以后，类似的数据模型得不到训练，最后在测试集上的表现肯定是不好的。我们对于这类数据做的处理是添加一些特征去标记它们。比较简单地可以使用顺序标签，标记它是第几次重复出现的。但是这样子简单的不一定够，大家可以自己去挖掘更深的特征去表达。</p>
<p><strong>统计特征的构建技巧(重要):</strong>因为我们要对每天进行统计，所以我建议大家把clicktime和conversiontime转化为这种形式，方便我们统计一些时间特征，也方便我们划分数据集：</p>
<p><img alt="image-20190405211407495" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190405211407495.png" /></p>
<p><strong>图模型特征:</strong>我们可以把业务转化为一个简单的图模型，然后在图模型里面找一些统计量来作为特征，通过图模型也可以更加深入的理解业务场景，我做个简单的示意图：</p>
<p><img alt="image-20190405211532618" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190405211532618.png" /></p>
<p>初步分析：上图是一个用户对一个时间窗口内的app的考察记录，app之间的箭头表示用户点击之间的跳转，在整个过程中，我们可以计算每个app的入度，这样可以找到哪个app更受此用户欢迎。</p>
<p>图模型是一个非常强的分析工具，比如你还可以加自环，这样可以看到用户的重复点击情况等等。</p>
<p><strong>大内存数据的处理办法: </strong><strong>特征处理</strong></p>
<p>在处理大规模原始数据时，需要充分借助外存（硬盘）空间，只把真正需要处理的数据放进内存。一般而言，采用流式、分块的方式处理数据可以解决大部分问题。以下是一些具体的技巧。</p>
<p><strong>a） 只加载需要的数据到内存。</strong>有些特征可以通过单条数据直接得到，如星期特征。这种情况下，可以使用 streaming 的方式进行处理，每次读入若干数据（chunk），处理，生成特征，然后再写到硬盘。使用 pandas 的 read_csv，可以设置 chunksize 参数，譬如 for chunk in read_csv ( infile, chunksize=10000 )；</p>
<p><strong>b） 只保留需要的数据在内存。</strong>决赛的数据可以直接装到 16G 内存中，每次生成一条样本的特征，就把特征直接写入硬盘，不在内存保留。如果生成的特征较多，可以分多次生成，写到分散的特征文件，最后进行一个 merge 操作。在 merge 的时候，可以对多个特征文件按照统一的 key 进行排序，然后同时扫描多个特征文件，进行merge，再写到硬盘；</p>
<p><strong>c） 充分利用排序加速。</strong>在上面的 streaming 处理方式中，有时预先对文件按照某些 key 排序，可以加速处理。譬如统计某个 user 在各个 clickTime 之前的平均转化率，可以对 train.csv 按照 user &amp; clickTime （当然可以结合其他的 key，如 positionID）进行排序，然后扫描文件进行统计。又譬如统计某个 user 在 clickTime 前安装的 app 数量，可以对 train.csv 和 user_app_actions.csv 同时按照 user &amp; time 进行排序，然后交替扫面两个文件，生成统计特征。对于排序操作，则可以直接使用 Linux 自带的 sort 命令，在小内存下完成排序操作。</p>
<p>综上，在处理大文件的时候，可以借鉴 split-apply-combine 的思路。</p>
<p>不少开源的工具支持外存和在线学习，使用这些工具，无需一次性把所有数据加载到内存，造成内存瓶颈。常用的一些工具如下：</p>
<p>a)     Vowpal Wabbit：支持 LR + 高阶特征组合，在线学习</p>
<p>b)     Libffm：支持外存学习</p>
<p>c)     XGBoost：支持外存学习</p>
<p>d)     Keras：通过模型的 fit_generator 方法，支持批量读入数据进行训练</p>
<p><strong>问一下，为什么统计历史转化率在全集上统计，和滑窗统计都会有效果，全集上统计不算人为数据泄露么？</strong></p>
<p>在全集上面统计，使用了过去和未来两部分数据，一般来说这两部分数据存在相关性。所以使用滑窗和全集统计，特征也有一定的相关性，可能都会有正向效果。但由于毕竟使用了未来的数据（实际业务场景中不会存在的数据），会造成数据泄露，高估结果。</p>
<p><strong>请问专家，那个贝叶斯平滑处理转化率数据的话，是按照划窗处理合适还是全集处理？全集处理会不会有点数据泄露？</strong></p>
<p>A：考虑下测试集是否会有这个信息？如果使用训练集的全集统计作为测试集的统计结果，其实这份特征的构建逻辑也是使用了过去的数据，那么在本地训练的时候也应该使用这样的特征抽取逻辑。</p>
<p><strong>由于特征交叉组合会产生组合爆炸，可以通过什么方法发现某个特征和某个特征的交叉组合有效，除了groupby</strong></p>
<p>A：可以使用一些常用的统计指标，或者 boxplot</p>
<p><strong>FM既然可以识别多个特征的交叉组合，是不是把原始特征放进去不用特征交叉组合达到的效果和加了各种特征组合的LR一样？还是说仍然需要特征交叉和组合。</strong></p>
<p>A：不用手动构造一些简单的交叉特征，譬如 x1 * x2；但是可能仍然需要手动抽取一些复杂的特征，譬如某个 userID 在某个 appID &amp; positionID 下的统计平均转化率</p>
<p><strong>Vowpal Wabbit：支持 LR + 高阶特征组合，在线学习这个有没有相关的资料。</strong></p>
<p>A：https://github.com/JohnLangford/vowpal_wabbit</p>
<p>这个是使用 vw+高阶特征组合的 criteo pctr 比赛第三名方案：https://github.com/songgc/display-advertising-challenge</p>
<p><strong>关于模型融合的方法和参数确定有没有好的资料可以参考？</strong></p>
<p>A：参考公众号之前的 kaggle 经验分享，http://mp.weixin.qq.com/s/BE1mfmKJTsDSwWi16mllNA</p>
<p>这里有一个很好的 survey：http://mlwave.com/kaggle-ensembling-guide/</p>
<p><strong>stacking的话模型有差的，加上会不会影响结果？</strong></p>
<p>A：stacking 要成功的一个很重要的条件是模型集合尽量 diverse，同时模型的性能不能相差太大。以正确率为例，90%融合80%可能比90%融合50%效果要好。模型差都是相对的，让你的 stacker 来告诉你这个“差”模型是否对模型集成有效果吧</p>
<p><strong>app稠密特征:</strong> 我们还尝试了用word embedding的思路从user_installapp表中提取相关的特征，用Wide &amp; Deep Model生成稠密特征。</p>
<p><strong>总结</strong>很简短：建议大家多观察数据，少无谓编码，多思考特征，少调整参数，多想，少试。</p>
<p><strong>节省内存的方法：</strong></p>
<p>\1. 我们是将数据按天进行划分来提取特征，那么对其他表merge之前，我们其实可以只留下在这一天中出现过的app、creativeID、positionID等等，这样能大幅减少计算量；</p>
<p>\2. 对两个表merge前我们只需要留下需要的那些列，比如只计算positionID的统计特征时，其他不相关的列（比如connectionType、creativeID等等）其实是可以删掉的；</p>
<p>\3. 我们提取的特征全部使用scipy的csr_matrix来存储，它转化成pandas的DataFrame也是非常快速的，提取完的特征通过numpy.savez保存至硬盘，这样读取时的效率非常高。</p>
<p><strong>冠军特征工程: </strong> 特征这一块可以说是我们的短板, 至今还不懂群里各位大佬说的trick。 我们的特征主要是一些基本的统计信息, 最好的单模型用到的特征算上原始特征只有40几维。 关于群里讨论最多的转化率, 我们试过全局统计, 窗口统计, 平滑与不平滑, 并没有发现太多的差异性。 目前我们采用的转化率是统计点击日之前的转化率, 不统计出现次数过少的, 这么做纯粹是因为简单, 速度快, 而且在我们的实验里效果并不差于那些复杂的手段, 可能在我们的模型里转化率并不重要。 其次, 我们也尝试过使用Word2vec, Doc2vec等思想为user, app学习低维向量特征, 但实验结果都不太理想, 我们已经放弃了使用安装列表。</p>
<p><strong>pandas的iterrows优化:</strong>如果不得不用迭代，比如重复点击的trick，我想了很多办法让它通过行操作实现，结果一直行不通。网上很多人会建议说用iterows，实际上即使是n级别的iterows都挺慢的。更好的方法是把Dataframe转换成dict，一个用10小时才能iterrows完的Dataframe，转换成dict可能只要1，2分钟可以迭代完。</p>
<p><strong>文件管理:</strong>这个是我个人的一个摸索出来的一个方式，也不知道专不专业。我的整个目录是</p>
<p><img alt="image-20190405214028128" src="http://spaceplayer.oss-cn-beijing.aliyuncs.com/spaceplayer/typora_img/面试准备/image-20190405214028128.png" /></p>
<p>final 放决赛的数据集，然后chmod –R 555，即没有写入权限，可以保护数据集。然后data再来放中间产生的数据集，然后code里面会有以数据集命名的代码先对每个表做一些简单处理，这样在之后的测试训练过程中，不用反复运行一些重复多余的运算。例如： ad.py</p>
<p><strong>请简要描述你们的解题思路及算法亮点，并具体谈一下特征抽取、训练模型的建立，以及模型的训练思想。</strong></p>
<p>大家的解题思路都比较相似。我们解题步骤分为数据预处理、数据去噪、特征提取、模型构建和模型融合5个部分。由于在特征上提出了稀疏特征的转化率编码方案，在模型上提出了nffm系列模型，并解决了一系列模型训练以及模型实现问题，我们才能取得好的成绩。特征抽取分为4个部分，即转化率、点击特征、安装特征和时间特征。模型上，我们采用了4种不同的模型，包括一个传统的GBDT模型，以及另外三个深度学习模型，分别是wide&amp;deep网络、pnn网络和nffm网络。GBDT模型我们使用的是lightgbm，而wide&amp;deep网络、pnn网络和nffm网络都是我们使用tensorflow和tflearn自己实现的，也正基于这点，使得我们很容易做模型改进、微调，这是非常有趣的事情。</p>
<p><strong>关于特征的提取</strong>，相信很多队伍也遇到过瓶颈。事实上，我们选择的方式是多思考赛题的实际意义。赛题要求是预测广告被点击后发生激活的概率，而用户点击广告后是否激活的一个主要驱动力就是用户对广告是否有需求，以及用户自身的安装力，所以用户的点击、安装历史以及用户针对具体某个App的点击安装历史尤为重要。基于这样的思考，我们构造出了一系列效果显著的特征，包括用户前一段时间内是否有点击、安装的记录；用户-App对是否在之前出现过、出现过多少次；用户-App对出现的次数等。此外，广告的位置信息也尤为重要。不同的广告位受到的关注度不同，所取得的推广效果也不同。</p>
<p>基于此，我们挖掘了数个与广告位相关的特征，包括转化率特征、历史点击量特征，以及用户、App与广告位的一些组合特征。此外，很多人都注意到了转化率特征的重要性，但很多人容易忽略的一点是用户的转化率特征。需要注意的是在利用用户转化率时需要进行恰当的分类，以免出现拟合的现象。</p>
<p><strong>请简要描述你们的解题思路及算法亮点，并具体谈一下特征抽取、训练模型的建立，以及模型的训练思想。</strong></p>
<p>我们的算法框架为：数据清洗、数据划分、特征提取、模型训练、模型融合。</p>
<p>数据清洗应该算是我们的一个亮点了。由于转化回流时间有长有短，所以最后五天的label可能是不准确的，尤其是第30天。如果将第30天的数据全部删除，将会丢失掉大量有用信息；如果全部保留，又引入了相当程度的噪声。而我们发现，转化回流时间是与App ID有关的。于是我们统计了每个App ID的平均转化回流时间，并且删除掉了第30天中平均转化回流时间偏长的数据。这样处理之后，性能稍微有了一些提升。</p>
<p>此外，此前介绍，我们对特征也进行了充分的分析。对于position ID的充分挖掘、对于用户交互历史的充分分析都为我们带来了显著的提升效果。此外还有交叉特征的转化率在后期也起到了一定的效果。</p>
<p>数据划分部分，由于机器条件的限制，我们使用了第26天-第30天的数据。关于训练集验证集的划分，我们采用的是5折交叉验证。</p>
<p>特征提取部分，我们将其分为四项：</p>
<p>1）基础特征，包括用户的基本特征、广告的基本特征、上下文特征；</p>
<p>2）统计特征，对基础特征进行交叉后再统计，包括count操作和unique操作；</p>
<p>3） 时间相关特征，主要统计了用户或用户-App在前一段时间内的点击次数或者安装次数；</p>
<p>4）概率估计特征，对很多ID类特征，包括交叉ID类特征做了概率估计。</p>
<p>模型训练部分，我们刚开始一直使用的是LightGBM，训练速度非常快，在验证特征有效性方面可以大大缩短时间。我们的模型融合采用的是Stacking方法。除了LightGBM之外，我们又训练了FFM、LR、GBDT、ET模型。最终Stacking帮助我们提高了2.5个万分点左右。</p>
<h4 id="lookalike">Lookalike算法[扩展]</h4>
<p><a href="https://www.jianshu.com/p/c7957ac169f1">Lookalike博文</a></p>
<p>第一种就是显性的定位，广告主根据用户的标签直接定位</p>
<p>第二种做法，通过一个机器学习的模型，来定位广告主的潜在用户</p>
<h5 id="lookalike_1">Lookalike入模特征</h5>
<h6 id="_15">行为结果数据</h6>
<p>所谓行为结果数据是已经采取了具体行动的数据，例如购买数据，入资数据等。</p>
<h6 id="_16">行为意向数据</h6>
<p>所谓行为意向数据是倾向于采取某种行为的人群数据，最典型的是搜索引擎的数据.</p>
<h6 id="_17">行为偏好数据</h6>
<p>从业务逻辑来说，具有某种偏好或者属于某种类型的人群往往会更倾向于购买某款产品，是广告主普遍选用的一种数据。</p>
<h6 id="_18">行为模式数据</h6>
<p>所谓行为模式是指通过分析消费者的行为与时间、空间的关系，以及一系列行为之间的时间和空间序列关系，总结出的具有一定一致性意义的行为表现，通过这些一致性模式预测相关行为, 目前还处在探索和优化阶段.</p>
<h5 id="lookaliketrick">Lookalike应用Trick</h5>
<h6 id="_19">结合聚类算法一起使用</h6>
<h6 id="_20">利用用户画像，给用户打标签，利用相同标签找到目标人群</h6>
<p><a href="https://zhuanlan.zhihu.com/p/25509178">微信朋友圈Lookalike</a></p>
<p><a href="http://www.yeolar.com/media/note/2016/12/04/bj2016-archsummit/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/%E5%BD%93%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%81%87%E4%B8%8A%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%A7%A3%E6%9E%90%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B%E5%9C%88%20lookalike%20%E7%AE%97%E6%B3%95.pdf">微信朋友圈LookalikePPT</a></p>
<p>社交同质性和社交影响力是社交关系数据的两个核心价值, 朋友圈广告重点会挖掘这两个价值</p>
<p>word2vec —&gt; node2vec</p>
<p>在图网络上按照一个搜索的方法生成节点序列，这个节点的序列可以对应到自然语言的一个句子，后面我们通过Word2Vec的框架，将节点embedding为一个向量。</p>
<p>所以对于做network embedding的时候，这个生成节点序列的搜索策略非常重要。最简单的一个方法，就是随机游走，随机游走一方面生成节点序列，另一方面也是对图的一种采样，降低了计算量。</p>
<p>随机游走的算法调整见上面链接</p>
<h3 id="_21">爱库存主页推荐项目</h3>
<p>社交电商是什么?</p>
<p>word2vec原理</p>
<p>解释auc</p>
<p>bandit算法</p>
<h3 id="_22">知识图谱助力电影推荐</h3>
<h2 id="_23">二、机器学习 深度学习</h2>
<h3 id="gbdt">GBDT</h3>
<h3 id="lightgbm">LightGBM</h3>
<h3 id="xgboost_1">XGBoost</h3>
<h2 id="_24">三、基础算法</h2>
<h2 id="_25">四、概率统计和矩阵</h2>
<h2 id="_26">五、推荐算法</h2>
<h2 id="cuda">六、CUDA编程</h2></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
